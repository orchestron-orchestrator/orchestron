import diff
import json
import logging
import testing
import xml

import yang
import yang.schema
import yang.adata
import yang.gdata

from orchestron.device_meta_config import orchestron_rfs__device_entry as DeviceMetaConfig

import netconf

DISCONNECTED  = 0
CONNECTING    = 1
CONNECTED     = 2
TRANSACTION   = 3

class DeviceSchema(object):
    name: str

    ## Schema namespaces
    schema_namespaces: set[str]

    ## Root of the config data tree
    # TODO: why is @property needed here?
    @property
    root: mut() -> yang.adata.MNode

    ## Workaround for "device_type.root.from_gdata" not working, I suspect
    ## because root.from_gdata is a static method .. This now points to the
    ## from_gdata static method on an aliased import of the root type, like this:
    # from foo.devices.bar_device_adata import root as bar_device_adata_root
    # ... = DeviceType(..., from_gdata=bar_device_adata_root.from_gdata, ...)
    # TODO: why is @property needed here?
    @property
    from_gdata: mut(?yang.gdata.Node) -> yang.adata.MNode

    ## Function to convert from XML to gdata using the DeviceType schema
    # TODO: why is @property needed here?
    @property
    from_xml: mut(xml.Node) -> yang.gdata.Container

    ## Function to convert from JSON to gdata using the DeviceType schema
    # TODO: why is @property needed here?
    @property
    from_json: mut(dict[str, ?value]) -> yang.gdata.Container

    ## Function to convert from XML to gdata using the DeviceType schema (schema-driven)
    # TODO: why is @property needed here?
    @property
    from_xml_gen3: mut(xml.Node, list[str]) -> yang.gdata.Container

    ## Function to convert from JSON to gdata using the DeviceType schema (schema-driven)
    # TODO: why is @property needed here?
    @property
    from_json_gen3: mut(dict[str, ?value], list[str]) -> yang.gdata.Container

    def __init__(self, name, schema_namespaces, root, from_gdata, from_xml=None, from_json=None, from_xml_gen3=None, from_json_gen3=None):
        self.name = name
        self.schema_namespaces = schema_namespaces
        self.root = root
        self.from_gdata = from_gdata
        self.from_xml = from_xml if from_xml is not None else lambda x: yang.gdata.Container()
        self.from_json = from_json if from_json is not None else lambda x: yang.gdata.Container()
        self.from_xml_gen3 = from_xml_gen3 if from_xml_gen3 is not None else lambda x, y: yang.gdata.Container()
        self.from_json_gen3 = from_json_gen3 if from_json_gen3 is not None else lambda x, y: yang.gdata.Container()


## DeviceType represents a type of device, i.e. a specific platform or
## implementation of a device. It is used to define the schema and
## adapter type for the device.
class DeviceType(object):
    ## Name of the device type
    name: str

    ## Adapter type, i.e. the DeviceAdapter subclass to use
    # TODO: why is @property needed here?
    @property
    adapter_type: proc(DeviceMgr, DeviceSchema, DeviceMetaConfig, logging.Handler, ?WorldCap) -> DeviceAdapter

    schema: DeviceSchema

    def __init__(self, name: str, adapter_type, schema_namespaces, root, from_gdata, from_xml=None, from_json=None, from_xml_gen3=None, from_json_gen3=None):
        self.name = name
        self.adapter_type = adapter_type
        self.schema = DeviceSchema(name, schema_namespaces, root, from_gdata, from_xml, from_json, from_xml_gen3, from_json_gen3)

class MockRoot(yang.adata.MNode):
    """Mock root node for mock devices"""
    def __init__(self):
        self._name = "dummy"
        self._ns = "dummy_ns"
        self._schema = None
        self._parent = None

    mut def to_gdata(self) -> yang.gdata.Node:
        return yang.gdata.Leaf("string", self._name)

    @staticmethod
    mut def from_gdata(self, gdata: ?yang.gdata.Node=None) -> yang.adata.MNode:
        return MockRoot()

    mut def prsrc(self, self_name='ad', top=False, list_element=False) -> str:
        return f"{self_name}.{self._name}"

class DeviceError(Exception):
    """Exception raised when the device configuration fails
    """

class TransientError(DeviceError):
    """Transient errors are temporary and can typically be recovered from by retrying
    """

class PermanentError(DeviceError):
    """Permanent errors are typically not recoverable

    Like the device things the configuration is invalid, which is not going to
    change no matter how many times we retry
    """

class NotConnectedError(TransientError):
    """The device is not connected
    """

class BusyError(TransientError):
    """The device is busy, i.e. it is currently processing a configuration transaction
    """

class LockedError(TransientError):
    """The device is locked, i.e. it is not possible to configure it at the moment
    """

class ConfigError(PermanentError):
    """Configuration error, i.e. the device rejected the configuration

    Retrying the same configuration typically does not help.

    Args:
        message (str): The error message from the device
        conf: The configuration sent to the device that caused the error,
            normally a diff computed from the current running configuration and
            the target configuration.
        target_conf: The target configuration, i.e. the configuration that we
            intended to have on the device, which is the entire declarative
            configuration for the device as outputted by transforms.
    """
    conf: ?yang.gdata.Node
    target_conf: ?yang.gdata.Node

    def __init__(self, message: str="", conf: ?yang.gdata.Node=None, target_conf: ?yang.gdata.Node=None):
        PermanentError.__init__(self, message)
        self.conf = conf
        self.target_conf = target_conf

class ModCap(object):
    name: str
    namespace: str
    revision: ?str
    feature: list[str]

    def __init__(self, name: str, namespace: str, revision: ?str=None, feature: list[str]=[]):
        self.name = name
        self.namespace = namespace
        self.revision = revision
        self.feature = feature

    def __str__(self) -> str:
        return f"ModCap(name={self.name}, namespace={self.namespace}, revision={self.revision}, feature={self.feature})"

extension ModCap(Eq):
    def __eq__(self, other: ModCap) -> bool:
        self_revision = self.revision
        other_revision = other.revision
        revision_eq = (self_revision is None and other_revision is None) or (self_revision is not None and other_revision is not None and self_revision == other_revision)
        return self.name == other.name and self.namespace == other.namespace and revision_eq and self.feature == other.feature


actor DeviceRegistry(dev_types: dict[str, DeviceType]={}, wcap: ?WorldCap=None, log_handler: logging.Handler):
    """Device Registry keeps track of all devices and hands out references to
    them based on name.

    There must only be a single Device instance per device, i.e. the same device
    name must always return the same Device instance.
    """
    var devices = {}

    action def _dummy_reconf(name: str):
        # Dummy reconf callback, used to avoid None
        pass

    var reconf_cb: action(str) -> None = _dummy_reconf

    def get(name: str) -> DeviceMgr:
        if name not in devices:
            devices[name] = DeviceMgr(dev_types, wcap, name, log_handler, reconf_cb)
        dev = devices[name]
        return dev

    def on_reconf(on_reconf: action(str) -> None):
        reconf_cb = on_reconf

def truncate_conf(conf: ?yang.gdata.Node) -> str:
    """Truncate the configuration to a short string for logging
    """
    if conf is not None:
        sc = conf.to_json()
        trunc_len = min([len(sc), 50])
        if trunc_len < len(sc):
            sc = sc[:trunc_len] + "..."
        return sc
    return r"{}"

actor DeviceMgr(dev_types: dict[str, DeviceType]={}, wcap: ?WorldCap=None, name: str, log_handler: logging.Handler, on_reconf: action(str) -> None):
    """Device Manager manages a device and represents that device, as an
    abstract device, in the system. Platform specific handling is implemented in
    the DeviceAdapter, i.e.  in subclasses of DeviceAdapter, like NetconfDriver
    and MockAdapter.

    The DeviceMgr sits between the TTT transaction engine and devices out in
    the real world. All changes from TTT are accepted, they are by definition
    the intended target configuration for the device, thus the TTT API is fairly
    simple. Configuration is fed from TTT to DeviceMgr asynchronously (nothing
    can go wrong) together with a transaction id (tid). If a TTT transaction
    wants to await the configuration to reach the device, that is possible via
    the wait_complete(tid). The device configuration interaction is serial,
    which means that we are either idling or have configuration in-transit to
    the device. If new configuration is received from TTT while we have
    configuration in-transit to the device, the new configuration is queued up
    and the associated transactions added to pending_txids. Once acknowledgement
    is received from the device, and thus the in-transit commit has concluded,
    the pending transactions, represented by target_conf, can be pushed to the
    device.

    The device interaction is entirely asynchronous.
    """
    _log_handler = logging.Handler(name)
    _log_handler.set_handler(log_handler)
    _log_handler.set_output_level(logging.DEBUG)
    _log = logging.Logger(_log_handler)

    mock = True if wcap is None else False
    _log.debug("DeviceMgr starting up", {"name": name, "mock": mock})

    # Orchestron's intended target configuration, that we want on the device.
    var target_conf: ?yang.gdata.Node = None

    # The device's meta configuration, like address, credentials, etc.
    var dmc: ?DeviceMetaConfig = None

    var schema: DeviceSchema = DeviceSchema("mock", set(), MockRoot, from_gdata=MockRoot.from_gdata)
    var adapter: DeviceAdapter = MockAdapter(self, schema, _log_handler, wcap) if mock else NoAdapter(self, schema, _log_handler, wcap)

    # The modules supported by the device.
    var modset: dict[str, ModCap] = {}
    var modset_id: ?str = None

    # current_txids are the ids of the transactions that are currently
    # in-transit, which also means that we can determine if we have an
    # outstanding transaction by checking len(current_txids) > 0.
    var current_txids = set()
    # pending_txids are the ids of the transactions that are pending, which
    # means these transactions arrived while we already had configuration
    # in-transit to the device. When len(pending_txids) > 0, we need to
    # send the latest configuration after the current transaction is done.
    var pending_txids = set()
    # Note how target_conf always only reflects the very latest configuration
    # that we received from the TTT transaction engine. When the device is ready
    # to receive configuration (we are connected, have said hello, gotten
    # capabilities, do not have an outstanding transaction), we will send the
    # target_conf. A snapshot is taken and sent to the device. We do not keep
    # that particular version. If later the device failed to commit the
    # configuration and we need to retry, we will retry with a new
    # configuration.

    var reconfigure_id = 0

    # TTT transactions can optionally request, through wait_complete(tid, cb), to
    # wait until configuration has been committed to the device. We keep track
    # of those callbacks keyed by tid.
    var callbacks: dict[str, action(value)->None] = {}

    def on_modset_update(new_modset: dict[str, ModCap]):
        _log.debug("Modset updated", {"new_modset": new_modset})
        on_reconf(name)

    def on_connect(new_modset: dict[str, ModCap]):
        _log.debug("Device connected", {"new_modset": new_modset})
        if modset_eq(modset, new_modset):
            _log.debug("Supported modules unchanged")
            if modset != {}:
                _log.debug("Sending config")
                _send_config()
        else:
            _log.debug("New supported modules, triggering RFS reconf", {"name": name})
            modset = new_modset
            modset_id = hash_modset(modset)
            on_reconf(name)
            return

    def set_dmc(new_dmc: DeviceMetaConfig) -> None:
        old_type = str(dmc.type) if dmc is not None else str(None)
        _log.debug("DeviceMgr.set_dmc", {"old_type": old_type, "new_dmc": json.encode(json.decode(new_dmc.to_gdata().to_json()), pretty=False)})

        if mock:
            _log.debug("DeviceMgr.set_dmc: mock device")
        else:
            new_dmc_type = new_dmc.type
            if new_dmc_type is not None:
                if old_type != str(new_dmc.type):
                    _log.debug("DeviceMgr type has changed, using new adapter", {"old_type": old_type, "new_type": new_dmc.type})

                    device_type = dev_types.get(new_dmc_type)
                    if device_type is not None:
                        adapter = device_type.adapter_type(self, device_type.schema, new_dmc, _log_handler, wcap)
                        _log.info("DeviceMgr.set_dmc: using adapter", {"adapter": adapter})
                        adapter.set_dmc(new_dmc)
                    else:
                        _log.warning("DeviceMgr.set_dmc: configured device type not available in system", {"device_type": new_dmc_type})
                else:
                    _log.debug("DeviceMgr.set_dmc: device type unchanged, not changing adapter")
            else:
                _log.debug("DeviceMgr.set_dmc: no device type configured, not changing adapter")

        adapter.set_dmc(new_dmc)

        dmc = new_dmc

    def _send_config():
        """Send configuration to the device adapter

        This function manages the transaction queue and calls the adapter's
        configure method with the current target configuration.
        """
        def on_done(error: ?Exception):
            """Handle transaction completion

            This callback is called when the adapter finishes the configuration
            transaction, either successfully or with an error.
            """
            if error is not None:
                if isinstance(error, NotConnectedError):
                    _log.debug("Device not connected, no need to retry - waiting for reconnect")
                    pending_txids.update(current_txids)
                    current_txids = set()

                elif isinstance(error, PermanentError):
                    _log.debug("Permanent error pushing configuration to device", {"error": error})
                    if isinstance(error, ConfigError):
                        _log.debug("Configuration failed due to bad config", {"error": error})

                    # Got a permanent error, giving up
                    for tid,callback in callbacks.items():
                        if tid in current_txids:
                            callback(error)
                            del callbacks[tid]

                    # TODO: uh, what else? we need to bubble up this sort of error state to an operator somehow

                    if len(pending_txids) > 0:
                        _log.debug("New intended configuration available, retrying with latest config")
                        pending_txids.update(current_txids)
                        current_txids = set()
                        _send_config()
                    else:
                        _log.debug("No new intended configuration available, no point in retrying with same conf")
                        pending_txids.update(current_txids)
                        current_txids = set()

                elif isinstance(error, TransientError):
                    _log.debug("Transient error", {"error": error})
                    if isinstance(error, BusyError):
                        _log.debug("DeviceAdapter busy, this should never happen")

                    if len(pending_txids) > 0:
                        _log.debug("New intended configuration available, retrying with latest config")
                        pending_txids.update(current_txids)
                        current_txids = set()
                        _send_config()
                    else:
                        retry_in = 1
                        _log.debug("No new intended configuration available. Scheduling retry of current config", {"retry_in": retry_in})
                        pending_txids.update(current_txids)
                        current_txids = set()
                        after retry_in: _send_config()

                else:
                    _log.debug("Unhandled error", {"error": error})
                    # Uh, this is indicative of programmer error and we should fix it, but let's do stupid retry as well
                    pending_txids.update(current_txids)
                    current_txids = set()
                    after 1: _send_config()

            else:
                _log.debug("Configuration successfully applied on device, calling callbacks...", {"txids": current_txids})
                for tid,callback in callbacks.items():
                    if tid in current_txids:
                        callback(True)
                        del callbacks[tid]
                current_txids = set()
                if len(pending_txids) > 0:
                    _log.debug("Configuration changed during in-progress transaction, running again...")
                    _send_config()

        # Check if we already have a transaction in progress
        if len(current_txids) > 0:
            _log.debug("DeviceMgr._send_config: there is currently an outstanding configuration, skipping", {"txids": current_txids})
        else:
            if target_conf is not None:
                current_txids = pending_txids
                pending_txids = set()
                _log.debug("DeviceMgr._send_config: sending intended target configuration", {"txids": current_txids})
                adapter.configure(on_done, target_conf)
            else:
                _log.debug("_send_config: target_conf not set")

    def configure(new_conf: ?yang.gdata.Node, conf_modset_id: ?str, tid: str="0"):
        pending_txids.add(tid)
        if new_conf is not None and conf_modset_id is not None:
            if conf_modset_id != modset_id:
                _log.debug("DeviceMgr.configure: modset_id mismatch, ignoring configuration", {"conf_modset_id": str(conf_modset_id), "modset_id": str(modset_id)})
                return
            _log.debug("DeviceMgr.configure: received new intended configuration", {"tid": tid, "new_conf": truncate_conf(new_conf)})
            target_conf = new_conf
            _send_config()
        elif new_conf is None and conf_modset_id is None:
            _log.debug("DeviceMgr.configure: transaction registered intent to configure but awaiting reconf", {"tid": tid})
        else:
            _log.debug("DeviceMgr.configure: invalid input", {"conf_modset_id": str(conf_modset_id), "new_conf": truncate_conf(new_conf), "tid": tid})

    def reconfigure(cb: ?action(?Exception) -> None):
        """Reconfigure the device with the current target configuration

        This can be called in order to ensure that the device is configured
        in accordance with the current target configuration. While configuration
        changes from within Orchestron naturally trigger configuration of the
        device, it is possible that the device drifts out of sync, for example
        due to manual changes on the device. Calling reconfigure() will push
        the current target configuration to the device again.
        """
        def cb_wrapper(result: value):
            if cb is not None:
                if isinstance(result, Exception):
                    cb(result)
                else:
                    cb(None)

        reconfigure_id += 1
        new_tid = "reconfigure-{reconfigure_id}"
        pending_txids.add(new_tid)
        _send_config()
        if cb is not None:
            wait_complete(new_tid, cb_wrapper)

    def wait_complete(tid: str, done: action(value)->None):
        if tid not in current_txids | pending_txids:
            _log.debug("DeviceMgr.wait_complete: transaction id not found, calling done", {"tid": tid})
            done(True) # Assume tid is very old and has already completed, thus respond immediately
        else:
            _log.debug("DeviceMgr.wait_complete: waiting for transaction to complete", {"tid": tid})
            callbacks[tid] = done

    def get_capabilities():
        return adapter.get_capabilities()

    def get_modules() -> (dict[str, ModCap], ?str):
        return modset, modset_id

    def get_config():
        """Get the running config of the device, from the adapter which keeps a cached version of it

        Note how this doesn't actually reach out to the device, but only fetches
        a local copy. However, since it is in the adapter contract to keep the
        local view of the config up to date, this is mostly quite safe!
        """
        return adapter.get_config()

    # TODO: make cb non-optional
    def fetch_config(done: action(?yang.gdata.Node, ?Exception) -> None) -> None:
        """Fetch the current configuration from the device
        """
        adapter.fetch_config(done)

    def get_schema():
        return schema


class DeviceAdapter(object):
    """Abstract base class for Device Adapters
    """
    _log_handler: logging.Handler
    _wcap: ?WorldCap

    set_dmc: proc(new_dmc: DeviceMetaConfig) -> None

    ## Configure the device with the given configuration
    ##
    ## :param done: callback to call when the configuration is done
    ## :param new_conf: the new configuration to apply
    configure: proc(done: action(?Exception) -> None, new_conf: yang.gdata.Node) -> None

    get_capabilities: proc() -> list[str]

    get_modules: proc() -> dict[str, ModCap]

    ## Get the current running config from the device
    ##
    ## :param done: callback to call when the operation is completed
    ##
    ## This is an async operation with the results available in the callback.
    fetch_config: proc(done: action(?yang.gdata.Node, ?Exception) -> None) -> None

    get_config: proc() -> ?yang.gdata.Node


class NoAdapter(DeviceAdapter):
    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, log_handler, wcap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._log = logging.Logger(self._log_handler)

    def set_dmc(self, new_dmc):
        self._log.debug("NoAdapter.set_dmc", {"new_dmc": new_dmc.to_gdata().to_json()})

    def configure(self, done, new_conf):
        # The NoAdapter cannot configure anything, so we just call done() with False
        done(NotConnectedError())

    def get_capabilities(self):
        return []

    def get_modules(self):
        return {}

    def fetch_config(self, done: ?action(?yang.gdata.Node, ?Exception) -> None = None):
        pass

    def get_config(self):
        pass


class MockAdapter(DeviceAdapter):
    """Mock device adapter
    """
    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, log_handler, wcap: ?WorldCap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._log = logging.Logger(self._log_handler)
        self._modset = {}
        self._dmc = None
        self._driver = MockDriver(self._dev, schema, self._log_handler, self._wcap)

    def set_dmc(self, new_dmc: DeviceMetaConfig):
        self._driver.set_dmc(new_dmc)

    def configure(self, done, new_conf):
        return self._driver.configure(done, new_conf)

    def get_capabilities(self) -> list[str]:
        return self._driver.get_capabilities()

    def get_modules(self) -> dict[str, ModCap]:
        return self._driver.get_modules()

    def fetch_config(self, done):
        return self._driver.fetch_config(done)

    def get_config(self):
        return self._driver.get_config()


actor MockDriver(dev: DeviceMgr, schema: DeviceSchema, log_handler: logging.Handler, wcap: ?WorldCap):
    _log = logging.Logger(log_handler)
    _log.info("MockDriver starting up")

    var dmc: ?DeviceMetaConfig = None
    var modset: dict[str, ModCap] = {}

    var conn_state: int = DISCONNECTED
    var running_conf: ?yang.gdata.Node = None

    def set_dmc(new_dmc):
        if dmc is not None and new_dmc is not None:
            old_dmcg = dmc.to_gdata()
            new_dmcg = new_dmc.to_gdata()
            if old_dmcg is not None and new_dmcg is not None:
                if yang.gdata.diff(old_dmcg, new_dmcg) is not None:
                    _log.debug("Device.set_dmc: ignoring new device meta-config identical to current device meta-config")
                    return
        _log.debug("MockAdapter.set_dmc", {"new_dmc": new_dmc.to_gdata().to_json()})
        _dmc = new_dmc

        preset_caps = []
        if "cisco-ios-xr" in new_dmc.mock.preset:
            preset_caps.extend([
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg?module=Cisco-IOS-XR-um-hostname-cfg&revision=2021-04-21",
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg?module=Cisco-IOS-XR-um-interface-cfg&revision=2022-07-11",
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-if-ipv4-cfg?module=Cisco-IOS-XR-um-if-ipv4-cfg&revision=2022-07-11",
            ])
        if "juniper-junos" in new_dmc.mock.preset:
            preset_caps.extend([
                "http://xml.juniper.net/netconf/junos/1.0",
                "http://xml.juniper.net/dmi/system/1.0",
            ])
        for cap in preset_caps:
            m = parse_cap(cap)
            modset[m.name] = m
            _log.debug("Adding preset cap", {"cap": m.name})
#
        if len(new_dmc.mock.module.elements) > 0:
            for mock_cap in new_dmc.mock.module.elements:
                m = ModCap(mock_cap.name, mock_cap.namespace, mock_cap.revision, mock_cap.feature)
                _log.debug("Adding mock cap", {"cap": m.name})
                modset[m.name] = m

        if len(modset) > 0:
            _log.debug("Mock capabilities set, \"connecting\"...")
            conn_state = CONNECTED
            dev.on_connect(modset)
        else:
            _log.debug("No mock capabilities set, idling as not connected")

    def configure(done, new_conf):
        if conn_state == CONNECTED:
            _log.debug("MockAdapter.configure: device 'connected', responding done")
            running_conf = new_conf
            done(None)
        else:
            _log.debug("MockAdapter.configure: device not connected")
            done(NotConnectedError())

    def get_capabilities():
        return []

    def get_modules():
        return modset

    def fetch_config(done):
        if done is not None:
            done(running_conf, None)

    def get_config():
        return running_conf


class NetconfAdapter(DeviceAdapter):

    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, init_dmc: DeviceMetaConfig, log_handler, wcap: ?WorldCap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._log = logging.Logger(self._log_handler)
        self._driver = NetconfDriver(self._dev, self._schema, init_dmc, self._log_handler, self._wcap)

    def set_dmc(self, new_dmc: DeviceMetaConfig):
        self._driver.set_dmc(new_dmc)

    def configure(self, done, new_conf):
        return self._driver.configure(done, new_conf)

    def get_capabilities(self) -> list[str]:
        return self._driver.get_capabilities()

    def get_modules(self) -> dict[str, ModCap]:
        return self._driver.get_modules()

    def fetch_config(self, done: ?action(?yang.gdata.Node, ?Exception) -> None) -> None:
        self._driver.fetch_config(done)

    def get_config(self):
        return self._driver.get_config()

    def close(self, on_close: ?action() -> None=None):
        """Close the connection to the device
        """
        self._driver.close(on_close)


actor NetconfDriver(dev: DeviceMgr, schema: DeviceSchema, init_dmc: DeviceMetaConfig, log_handler: logging.Handler, wcap: ?WorldCap):
    """NETCONF device adapter

    It is possible to configure a device using different transaction commit
    procedures. Devices that have the writable-running capability allow
    edit-config RPC to directly target the running datastore so that we can push
    an entire configuration in a single operation which implicitly also
    "commits". This is often ideal since we can easily form the complete
    configuration as a single config payload to apply with a single RPC.

    Many devices support a candidate datastore ("candidate" capability) to which
    configuration can first be pushed, possibly using multiple edit-config
    calls, and then committed at which point the configuration goes from the
    candidate datastore to running. This mimics CLI use by a human where a
    configuration session to candidate allows editing the configuration in
    multiple operations and reviewing the result before a commit is performed.
    There is no real inherent benefit of using candidate mode for a system like
    Orchestron, the one exception being that it enables the use of confirmed
    commits (another capability).

    Confirmed commits enables a confirmation timeout for a commit, so that after
    the commit is performed, it must be confirmed within this time period or it
    is rolled back. This allows the device to rollback a potentially bad change
    if it means we lost connectivity to the device and thus we weren't able to
    confirm the commit. This is ideal from a network automation perspective
    since we get sort of built-in support for rolling back bad changes.

    Some devices do not support writable-running but do support candidate, such
    as IOS XR, which forces us to always go through the candidate datastore.

    In order of preference, we have these alternative commit procedures:
    - write to candidate + confirmed-commit, if confirmed-commit is supported
    - write directly to running, if writable-running is supported
    - write to candidate + commit

    What we actually push to the device is a diff that is computed based on the
    current running configuration which we fetch from the device and the new
    target configuration that we computed from the transforms in the TTT
    transaction engine. The diff is then pushed to the device. To ensure correct
    operations, we take a lock on the datastore on the device for the duration
    of the entire commit procedure.

    """
    _log = logging.Logger(log_handler)
    _log.info("NetconfDriver starting up")

    # The currently running configuration on the device (which in NMDA lingo is
    # the "intended configuration" of the device)
    var running_conf: ?yang.gdata.Node = None

    # The device's meta configuration, like address, credentials, etc.
    var dmc: DeviceMetaConfig = init_dmc

    # The NETCONF client connection to the device
    var client: ?netconf.Client = None

    var state: int = DISCONNECTED

    var modset: dict[str, ModCap] = {}

    NS_NC_1_0 = "urn:ietf:params:xml:ns:netconf:base:1.0"

    def _on_connect(c: netconf.Client, err):
        if client is not None and c is not client:
            _log.debug("Device._on_connect: ignoring connection from old client")
            return

        if err is not None:
            if state == CONNECTING:
                _log.error("Device._on_connect: error connecting to device", {"error": str(err)})
            else:
                _log.debug("Device._on_connect: connection failed", {"error": str(err)})
            modset = {}
            if client is not None:
                after 1: client.restart()
            return
        else:
            _log.info("Device._on_connect: connected to device")
            state = CONNECTED

            new_modset: dict[str, ModCap] = {}
            for cap in c.get_capabilities():
                m = parse_cap(cap)
                new_modset[m.name] = m

            # TODO: check yang-library instead!!

            if not modset_eq(modset, new_modset):
                modset = new_modset

            dev.on_connect(modset)

    def _on_notif(c, n):
        if client is not None and c is not client:
            _log.debug("Device._on_connect: ignoring connection from old client")
            return
        _log.debug("Notification from device")

    def set_dmc(new_dmc: DeviceMetaConfig):
        _log.debug("Device.set_dmc", {"dmc": dmc.to_gdata().to_json(), "new_dmc": new_dmc.to_gdata().to_json()})
        # TODO: implement Eq for adata
        #if dmc is not None and dmc == new_dmc:
        if dmc is not None and new_dmc is not None:
            old_dmcg = dmc.to_gdata()
            new_dmcg = new_dmc.to_gdata()
            if old_dmcg is not None and new_dmcg is not None:
                if old_dmcg == new_dmcg:
                    _log.debug("Device.set_dmc: ignoring new device meta-config identical to current device meta-config")
                    return

        _connect(new_dmc)
        dmc = new_dmc

    def _connect(new_dmc):
        if not len(new_dmc.address.elements) > 0:
            _log.debug("Not enough addressess :/")
            return

        addr = new_dmc.address.elements[0]
        address = addr.address
        addr_port = addr.port
        port = int(addr_port) if addr_port is not None else 830
        username = new_dmc.credentials.username
        password = new_dmc.credentials.password

        # TODO: we only need o use a new client if connection parameters have
        # changed, other settings don't require a new client

        if wcap is not None and username is not None and password is not None:
            state = CONNECTING
            _log.debug(f"Setting up NETCONF client... {address} {port} {username} {password}")
            c = netconf.Client(wcap, address, port, username, password,
                               skip_host_key_check=True,
                               on_connect=_on_connect,
                               on_notif=_on_notif,
                               log_handler=log_handler)
            client = c

    # TODO: Close protocol
    def close(on_close: ?action() -> None=None):
        """Close the connection to the device
        """
        _log.debug("Device.close")
        if client is not None:
            client.close()
            state = DISCONNECTED
            _log.debug("Device closed")
        else:
            _log.debug("Device.close: No client, nothing to close")
        if on_close is not None:
            on_close()

    # TODO: Restart protocol
    def restart():
        """Close the existing connection and reconnect to the device
        """
        _log.debug("Device.restart")
        new_dmc = dmc
        close(lambda: _connect(new_dmc))

    def configure(done: action(?Exception) -> None, new_conf: yang.gdata.Node):
        """Configure the device with a new configuration

        This starts a multi-step transaction process:
        1. Lock the datastore
        2. Fetch current config from device
        3. Compute diff between current and target
        4. Send diff via edit-config
        5. Commit (if using candidate datastore)
        6. Unlock datastore
        """
        _log.debug("Device.configure: received new configuration")

        # Check state
        if state != CONNECTED:
            if state == DISCONNECTED:
                _log.debug("Device.configure: device not connected, cannot send configuration")
                done(NotConnectedError())
            else:
                _log.debug("Device.configure: Already in transaction, cannot send configuration")
                done(BusyError())
            return

        # Set transaction state
        state = TRANSACTION

        def on_locked_running(c: netconf.Client, error: ?netconf.NetconfError):
            """Callback after locking running datastore"""
            _log.debug("Device.configure.on_locked_running", {"error": error})
            if error is not None:
                abort(error)
            else:
                if target_datastore() == "candidate":
                    # Now lock candidate as well
                    _log.debug("Device.configure: locking candidate datastore")
                    c.lock(on_locked_candidate, "candidate")
                else:
                    # Just running is enough, fetch the config
                    _log.debug("Device.configure: fetching current config from running")
                    c.get_config(on_fetched, "running")

        def on_locked_candidate(c: netconf.Client, error: ?netconf.NetconfError):
            """Callback after locking candidate datastore"""
            _log.debug("Device.configure.on_locked_candidate", {"error": error})
            if error is not None:
                # If we had locked running first, unlock it
                if has_writable_running():
                    c.unlock(lambda c, e: abort(error), "running")
                else:
                    abort(error)
            else:
                _log.debug("Device.configure: fetching current config from running")
                c.get_config(on_fetched, "running")

        def on_fetched(c: netconf.Client, r: ?xml.Node):
            _log.debug("Device.configure.on_fetched", {"r": r.encode() if r is not None else "None"})
            if r is not None:
                # TODO: inspect returned value for ok/errors
                current = schema.from_xml(r.children[0])
                if current is not None:
                    _log.debug("Device.configure: computing diff")
                    try:
                        new_conf2 = config_fixer(current, new_conf)
                        d = yang.gdata.diff(current, new_conf2)
                        xml_diff = d.to_xmlstr(pretty=False) if d is not None else ""
                        if xml_diff != "":
                            _log.debug("Device.configure: sending diff", {"diff": xml_diff})
                            c.edit_config(xml_diff, on_edited, target_datastore())
                        else:
                            _log.debug("Device.configure: no changes needed")
                            complete(c)
                    except ValueError as exc:
                        _log.error("Device.configure: Failed to compute diff", {"current": current.prsrc(), "target": new_conf.prsrc(), "exc": exc})
                        # TODO: should be DeviceError
                        abort(ValueError("Failed to compute diff"))
                else:
                    _log.error("Device.configure: failed to parse config", {"current": current, "target": new_conf})
                    # TODO: should be DeviceError
                    abort(ValueError("Failed to parse config"))
            else:
                _log.error("Device.configure: device disconnected during get-config")
                abort(NotConnectedError())

        def on_edited(c: netconf.Client, r: ?xml.Node):
            _log.debug("Device.configure.on_edited", {"r": r.encode() if r is not None else "None"})
            if r is not None:
                # TODO: inspect returned value for ok/errors
                if target_datastore() == "candidate":
                    _log.debug("Device.configure: committing to candidate")
                    c.commit(on_committed)
                else:
                    _log.debug("Device.configure: edit-config complete (writable-running)")
                    complete(c)
            else:
                _log.error("Device.configure: device disconnected during edit-config")
                abort(NotConnectedError())

        def on_committed(c: netconf.Client, r: ?xml.Node):
            _log.debug("Device.configure.on_committed", {"r": r.encode() if r is not None else "None"})
            if r is not None:
                # Check for errors in commit response
                has_error = False
                error_tag = None
                for child in r.children:
                    if child.tag == "rpc-error":
                        has_error = True
                        _log.error("Device.configure: commit error", {"error": child.encode()})
                        # Extract error-tag to determine the type of error
                        for error_child in child.children:
                            if error_child.tag == "error-tag":
                                error_tag = error_child.text
                                break
                        break

                if has_error:
                    _log.debug("Device.configure: discarding changes after failed commit")
                    # Check if the error is due to locked datastore
                    if error_tag == "in-use":
                        c.discard_changes(lambda c, r: abort(LockedError("Datastore is locked")))
                    else:
                        c.discard_changes(lambda c, r: abort(ConfigError("Commit failed", conf=new_conf, target_conf=new_conf)))
                else:
                    _log.debug("Device.configure: commit successful")
                    complete(c)
            else:
                _log.error("Device.configure: device disconnected during commit")
                abort(NotConnectedError())

        def complete(c: netconf.Client):
            """Successfully complete the transaction"""
            _log.debug("Device.configure: transaction complete, unlocking")

            def on_candidate_unlocked(c2: netconf.Client, e: ?netconf.NetconfError):
                # If we locked running, unlock it after candidate (reverse order of locking)
                if has_writable_running():
                    c2.unlock(lambda c3, e2: finish(e if e is not None else e2), "running")
                else:
                    finish(e)

            if use_locks():
                if target_datastore() == "candidate":
                    # Unlock candidate first
                    c.unlock(on_candidate_unlocked, "candidate")
                elif has_writable_running():
                    # Just unlock running (we were using writable-running)
                    c.unlock(lambda c, e: finish(e), "running")
                else:
                    # Shouldn't happen, but handle gracefully
                    finish()
            else:
                finish()

        def abort(err: Exception):
            """Abort and cleanup the transaction"""
            _log.debug("Device.configure: aborting transaction", {"error": err})

            def on_abort_candidate_unlocked(c: netconf.Client, e: ?netconf.NetconfError):
                # If we locked running, unlock it after candidate (reverse order)
                if has_writable_running():
                    c.unlock(lambda c2, e2: finish(err), "running")
                else:
                    finish(err)

            if client is not None:
                if target_datastore() == "candidate":
                    # Unlock candidate first
                    client.unlock(on_abort_candidate_unlocked, "candidate")
                elif has_writable_running():
                    # Just unlock running (we were using writable-running)
                    client.unlock(lambda c, e: finish(err), "running")
                else:
                    # No locks to release
                    finish(err)
            else:
                finish(err)

        def finish(error: ?Exception=None):
            """Final cleanup and state reset"""
            _log.debug("Device.configure: finishing transaction", {"error": error})
            # Reset state to CONNECTED
            state = CONNECTED
            # Call the done callback
            done(error)
            # Refresh running_conf if successful
            # TODO: feels redundant to refetch whole config here from device,
            # running_conf should really be target_conf at this point - keeping this for now though
            if client is not None and error is None:
                client.get_config(_on_get_config)

        # Start the transaction by locking the datastore(s)
        # Lock running if it's writable (to prevent others from directly editing it)
        # Otherwise, just lock the target datastore
        if client is not None:
            if use_locks():
                if has_writable_running():
                    _log.debug("Device.configure: starting transaction, locking running datastore")
                    client.lock(on_locked_running, "running")
                elif target_datastore() == "candidate":
                    _log.debug("Device.configure: starting transaction, locking candidate datastore only")
                    client.lock(on_locked_candidate, "candidate")
                else:
                    # This shouldn't happen - we should have either writable-running or candidate
                    _log.error("Device.configure: No lockable datastore available")
                    abort(ValueError("No lockable datastore available"))
            else:
                _log.error("Device.configure: Not using locks, getting config")
                client.get_config(on_fetched, "running")


    def get_capabilities():
        if client is not None:
            return client.get_capabilities()
        return []

    def get_modules():
        return modset

    def use_locks():
        # TODO: enable locks per default? or config option?
        # Locking is disabled per default.
        return False
        # Nokia SR Linux seems to be broken. The first commit dance in a NETCONF
        # session always seem to work, but if we have first acquired the lock on
        # candidate (Nokia SRL has candidate, not writable-running), the second
        # commit fails with a cryptic error message:
        # <rpc-error>
        #     <error-type>application</error-type>
        #     <error-tag>operation-failed</error-tag>
        #     <error-severity>error</error-severity>
        #     <error-message>
        #     Error [InvalidArgument]: Cannot discard candidate without starting a configuration session (request session id 17)
        #     </error-message>
        # </rpc-error>
        if is_nokia_srl():
            return False
        return True

    def target_datastore():
        # In order of preference, we have these alternative commit procedures:
        # - write to candidate + confirmed-commit, if confirmed-commit is supported
        # - write directly to running, if writable-running is supported
        # - write to candidate + commit
        if has_confirmed_commit() and has_candidate():
            return "candidate"
        elif has_writable_running():
            return "running"
        elif has_candidate():
            return "candidate"

        raise ValueError("No writable datastore available")

    def has_candidate():
        return "urn:ietf:params:netconf:capability:candidate:1.0" in modset

    def has_confirmed_commit():
        return "urn:ietf:params:netconf:capability:confirmed-commit:1.0" in modset

    def has_writable_running():
        return "urn:ietf:params:netconf:capability:writable-running:1.0" in modset

    def is_nokia_srl():
        return "srl_nokia-aaa" in modset

    def _on_get_config(c, r, cb: ?action(?yang.gdata.Node, ?Exception) -> None=None):
        _log.debug("Device._on_get_config")
        if r is not None:
            _log.debug("Device._on_get_config: r is not None")
            if r.tag == "rpc-reply" and len(r.children) == 1 and r.children[0].tag == "data":
                _log.debug("Device._on_get_config", {"r": r.encode()})
                running_conf = schema.from_xml_gen3(r.children[0], [])
                if cb is not None:
                    cb(running_conf, None)
            else:
                _log.error("Device._on_get_config", {"r": r.encode()})
                if cb is not None:
                    cb(None, ValueError("Unexpected response to <get-config>"))

    # TODO: done callback should not be optional
    # TODO: move _on_get_config to nested function under fetch_config
    def fetch_config(done: ?action(?yang.gdata.Node, ?Exception) -> None) -> None:
        _log.debug("Device._fetch_config")
        if client is not None:
            client.get_config(lambda c, r: _on_get_config(c, r, done))

    def get_config():
        return running_conf

    _connect(dmc)


def hash_modset(modset: dict[str, ModCap]) -> str:
    # TODO: use a better hash function
    # We use map here instead of a list comprehension to avoid creating the
    # intermediate list of strings. Ideally we could achieve the same with a
    # generator expression.
    modset_str = map(lambda m: str(modset[m]), sorted(modset.keys()))
    return str(hash("".join(modset_str)))

def modset_eq(a: dict[str, ModCap], b: dict[str, ModCap]) -> bool:
    if len(a) != len(b):
        return False
    if set(a.keys()) != set(b.keys()):
        return False
    for k in a.keys():
        if a[k] != b[k]:
            return False
    return True


def parse_cap(tcap: str) -> ModCap:
    parts = tcap.split("?", 1)

    name = parts[0]
    namespace = parts[0]
    revision = None
    feature = []

    qps = {}
    if len(parts) > 1:
        qparts = parts[1].split("&")
        for qpart in qparts:
            qkvparts = qpart.split("=")
            if len(qkvparts) == 2:
                qk, qv = qkvparts[0], qkvparts[1]
                qps[qk] = qv

    if "module" in qps:
        name = qps["module"]
    if "revision" in qps:
        revision = qps["revision"]

    return ModCap(name, namespace, revision, feature)


def _test_parse_cap_base():
    mod = parse_cap("urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.name, "urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.namespace, "urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.revision, None)
    testing.assertEqual(mod.feature, [])

def _test_parse_cap_xr_isis():
    mod = parse_cap("http://cisco.com/ns/yang/Cisco-IOS-XR-isis-act?module=Cisco-IOS-XR-isis-act&revision=2019-10-01")
    testing.assertEqual(mod.name, "Cisco-IOS-XR-isis-act")
    testing.assertEqual(mod.namespace, "http://cisco.com/ns/yang/Cisco-IOS-XR-isis-act")
    testing.assertEqual(mod.revision, "2019-10-01")
    testing.assertEqual(mod.feature, [])

def _test_parse_cap_xr_hostname():
    mod = parse_cap("http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg?module=Cisco-IOS-XR-um-hostname-cfg&revision=2021-04-21")
    testing.assertEqual(mod.name, "Cisco-IOS-XR-um-hostname-cfg")
    testing.assertEqual(mod.namespace, "http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg")
    testing.assertEqual(mod.revision, "2021-04-21")
    testing.assertEqual(mod.feature, [])

def config_fixer(current: yang.gdata.Node, new: yang.gdata.Node):
    # Fix up config. On IOS XR we need to bring with us the Mgmt interface
    # configuration that exists on the device. We run XRds for testing using
    # containerlab and containerlab configures the IP addresses as part of a
    # bootstrap process. The IP addresses are dynamically allocated and thus
    # vary between test invocations. Since our transform output does not contain
    # any configuration of the MgmtEth0/RP0/CPU0/0 interface, the diff will
    # remove it. If we deconfigure the interface from the device, we loose
    # connectivity to it. This code simply finds if there is a
    # MgmtEth0/RP0/CPU0/0 interface in the currently running configuraton on the
    # device and then brings that over into the new target config.
    def get_xr_mgmt_interface(n: yang.gdata.Node) -> yang.gdata.Node:
        xr_interfaces = n.children["interfaces"]
        if xr_interfaces.ns != "http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg":
            raise ValueError("No XR interfaces found")
        xr_interface = xr_interfaces.children["interface"]
        if isinstance(xr_interface, yang.gdata.List):
            for elem in xr_interface.elements:
                if_name = elem.get_leaf("interface-name").val
                if isinstance(if_name, str):
                    if if_name == "MgmtEth0/RP0/CPU0/0":
                        return yang.gdata.Container({
  'interfaces': yang.gdata.Container({
    'interface': yang.gdata.List(['interface-name'], elements=[elem])
  }, ns='http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg', module='Cisco-IOS-XR-um-interface-cfg')
})
        raise ValueError("No XR mgmt interface found")

    try:
        mgmt_intf_cfg = get_xr_mgmt_interface(current)
        new2 = yang.gdata.patch(new, mgmt_intf_cfg)
        if new2 is not None:
            return new2
        raise ValueError("Unreachable, patch will never produce empty (None) config for this config input")
    except Exception as exc:
        pass
    return new
