import diff
import hash.wyhash as wyhash
import json
import logging
import testing
import xml

import yang
import yang.schema
import yang.adata
import yang.gdata

from orchestron.device_meta_config import \
    orchestron_rfs__device_entry as DeviceMetaConfig, \
    orchestron_rfs__device__credentials as Credentials, \
    orchestron_rfs__device__mock as Mock

import netconf

DISCONNECTED  = 0
CONNECTING    = 1
CONNECTED     = 2
TRANSACTION   = 3

class DeviceSchema(object):
    name: str

    ## Schema namespaces
    schema_namespaces: set[str]

    ## Root of the config data tree
    # TODO: why is @property needed here?
    @property
    root: mut() -> yang.adata.MNode

    ## Workaround for "device_type.root.from_gdata" not working, I suspect
    ## because root.from_gdata is a static method .. This now points to the
    ## from_gdata static method on an aliased import of the root type, like this:
    # from foo.devices.bar_device_adata import root as bar_device_adata_root
    # ... = DeviceType(..., from_gdata=bar_device_adata_root.from_gdata, ...)
    # TODO: why is @property needed here?
    @property
    from_gdata: mut(?yang.gdata.Node) -> yang.adata.MNode

    ## Function to convert from XML to gdata using the DeviceType schema
    # TODO: why is @property needed here?
    @property
    from_xml: mut(xml.Node) -> yang.gdata.Container

    ## Function to convert from JSON to gdata using the DeviceType schema
    # TODO: why is @property needed here?
    @property
    from_json: mut(dict[str, ?value]) -> yang.gdata.Container

    def __init__(self, name, schema_namespaces, root, from_gdata, from_xml=None, from_json=None):
        self.name = name
        self.schema_namespaces = schema_namespaces
        self.root = root
        self.from_gdata = from_gdata
        self.from_xml = from_xml if from_xml is not None else lambda x: yang.gdata.Container()
        self.from_json = from_json if from_json is not None else lambda x: yang.gdata.Container()


## DeviceType represents a type of device, i.e. a specific platform or
## implementation of a device. It is used to define the schema and
## adapter type for the device.
class DeviceType(object):
    ## Name of the device type
    name: str

    ## Adapter type, i.e. the DeviceAdapter subclass to use
    # TODO: why is @property needed here?
    @property
    adapter_type: proc(DeviceMgr, DeviceSchema, DeviceMetaConfig, logging.Handler, ?WorldCap) -> DeviceAdapter

    schema: DeviceSchema

    def __init__(self, name: str, adapter_type, schema_namespaces, root, from_gdata, from_xml=None, from_json=None):
        self.name = name
        self.adapter_type = adapter_type
        self.schema = DeviceSchema(name, schema_namespaces, root, from_gdata, from_xml, from_json)

class MockRoot(yang.adata.MNode):
    """Mock root node for mock devices"""
    def __init__(self):
        self._name = "dummy"
        self._ns = "dummy_ns"
        self._schema = None
        self._parent = None

    mut def to_gdata(self) -> yang.gdata.Node:
        return yang.gdata.Leaf("string", self._name)

    @staticmethod
    mut def from_gdata(self, gdata: ?yang.gdata.Node=None) -> yang.adata.MNode:
        return MockRoot()

    mut def prsrc(self, self_name='ad', top=False, list_element=False) -> str:
        return f"{self_name}.{self._name}"

class DeviceError(Exception):
    """Exception raised when the device configuration fails
    """

class TransientError(DeviceError):
    """Transient errors are temporary and can typically be recovered from by retrying
    """

class PermanentError(DeviceError):
    """Permanent errors are typically not recoverable

    Like the device things the configuration is invalid, which is not going to
    change no matter how many times we retry
    """

class NotConnectedError(TransientError):
    """The device is not connected
    """

class BusyError(TransientError):
    """The device is busy, i.e. it is currently processing a configuration transaction
    """

class LockedError(TransientError):
    """The device is locked, i.e. it is not possible to configure it at the moment
    """

class TxidMismatchError(TransientError):
    """The device's txid doesn't match the expected txid, configuration drift detected
    """

class ConfigError(PermanentError):
    """Configuration error, i.e. the device rejected the configuration

    Retrying the same configuration typically does not help.

    Args:
        message (str): The error message from the device
        conf: The configuration sent to the device that caused the error,
            normally a diff computed from the current running configuration and
            the target configuration.
        target_conf: The target configuration, i.e. the configuration that we
            intended to have on the device, which is the entire declarative
            configuration for the device as outputted by transforms.
    """
    conf: ?yang.gdata.Node
    target_conf: ?yang.gdata.Node

    def __init__(self, message: str="", conf: ?yang.gdata.Node=None, target_conf: ?yang.gdata.Node=None):
        PermanentError.__init__(self, message)
        self.conf = conf
        self.target_conf = target_conf

class ModCap(object):
    name: str
    namespace: str
    revision: ?str
    feature: list[str]

    def __init__(self, name: str, namespace: str, revision: ?str=None, feature: list[str]=[]):
        self.name = name
        self.namespace = namespace
        self.revision = revision
        self.feature = feature

    def __str__(self) -> str:
        return f"ModCap(name={self.name}, namespace={self.namespace}, revision={self.revision}, feature={self.feature})"

extension ModCap(Eq):
    def __eq__(self, other: ModCap) -> bool:
        self_revision = self.revision
        other_revision = other.revision
        revision_eq = (self_revision is None and other_revision is None) or (self_revision is not None and other_revision is not None and self_revision == other_revision)
        return self.name == other.name and self.namespace == other.namespace and revision_eq and self.feature == other.feature


actor DeviceRegistry(dev_types: dict[str, DeviceType]={}, wcap: ?WorldCap=None, log_handler: logging.Handler):
    """Device Registry keeps track of all devices and hands out references to
    them based on name.

    There must only be a single Device instance per device, i.e. the same device
    name must always return the same Device instance.
    """
    var devices = {}

    action def _dummy_reconf(name: str):
        # Dummy reconf callback, used to avoid None
        pass

    var reconf_cb: action(str) -> None = _dummy_reconf

    def get(name: str) -> DeviceMgr:
        if name not in devices:
            devices[name] = DeviceMgr(dev_types, wcap, name, log_handler, reconf_cb)
        dev = devices[name]
        return dev

    def on_reconf(on_reconf: action(str) -> None):
        reconf_cb = on_reconf

def truncate_conf(conf: ?yang.gdata.Node) -> str:
    """Truncate the configuration to a short string for logging
    """
    if conf is not None:
        sc = conf.to_json()
        trunc_len = min([len(sc), 50])
        if trunc_len < len(sc):
            sc = sc[:trunc_len] + "..."
        return sc
    return r"{}"

actor DeviceMgr(dev_types: dict[str, DeviceType]={}, wcap: ?WorldCap=None, name: str, log_handler: logging.Handler, on_reconf: action(str) -> None):
    """Device Manager manages a device and represents that device, as an
    abstract device, in the system. Platform specific handling is implemented in
    the DeviceAdapter, i.e.  in subclasses of DeviceAdapter, like NetconfDriver
    and MockAdapter.

    The DeviceMgr sits between the TTT transaction engine and devices out in
    the real world. All changes from TTT are accepted, they are by definition
    the intended target configuration for the device, thus the TTT API is fairly
    simple. Configuration is fed from TTT to DeviceMgr asynchronously (nothing
    can go wrong) together with a transaction id (tid). If a TTT transaction
    wants to await the configuration to reach the device, that is possible via
    the wait_complete(tid). The device configuration interaction is serial,
    which means that we are either idling or have configuration in-transit to
    the device. If new configuration is received from TTT while we have
    configuration in-transit to the device, the new configuration is queued up
    and the associated transactions added to pending_txids. Once acknowledgement
    is received from the device, and thus the in-transit commit has concluded,
    the pending transactions, represented by target_conf, can be pushed to the
    device.

    The device interaction is entirely asynchronous.
    """
    _log_handler = logging.Handler(name)
    _log_handler.set_handler(log_handler)
    _log_handler.set_output_level(logging.DEBUG)
    _log = logging.Logger(_log_handler)

    mock = True if wcap is None else False
    _log.debug("DeviceMgr starting up", {"name": name, "mock": mock})

    # Orchestron's intended target configuration, that we want on the device.
    var target_conf: ?yang.gdata.Node = None
    # The device's current running configuration, as we know it.
    var running_conf: ?yang.gdata.Node = None

    # The device's meta configuration, like address, credentials, etc.
    var dmc: DeviceMetaConfig = DeviceMetaConfig(name, Credentials("", None))

    var schema: DeviceSchema = DeviceSchema("mock", set(), MockRoot, from_gdata=MockRoot.from_gdata)
    var adapter: DeviceAdapter = MockAdapter(self, schema, _log_handler, wcap) if mock else NoAdapter(self, schema, _log_handler, wcap)

    # The modules supported by the device.
    var modset: dict[str, ModCap] = {}
    var modset_id: ?str = None

    # current_txids are the ids of the transactions that are currently
    # in-transit, which also means that we can determine if we have an
    # outstanding transaction by checking len(current_txids) > 0.
    var current_txids = set()
    # pending_txids are the ids of the transactions that are pending, which
    # means these transactions arrived while we already had configuration
    # in-transit to the device. When len(pending_txids) > 0, we need to
    # send the latest configuration after the current transaction is done.
    var pending_txids = set()
    # Note how target_conf always only reflects the very latest configuration
    # that we received from the TTT transaction engine. When the device is ready
    # to receive configuration (we are connected, have said hello, gotten
    # capabilities, do not have an outstanding transaction), we will send the
    # target_conf. A snapshot is taken and sent to the device. We do not keep
    # that particular version. If later the device failed to commit the
    # configuration and we need to retry, we will retry with a new
    # configuration.

    # The last successfully sent diff. We use this to detect and break infinite
    # loops in the device config reconciliation loop
    var last_sent_diff: ?yang.gdata.Node = None

    var reconfigure_id = 0

    # TTT transactions can optionally request, through wait_complete(tid, cb), to
    # wait until configuration has been committed to the device. We keep track
    # of those callbacks keyed by tid.
    var callbacks: dict[str, action(value)->None] = {}

    def on_modset_update(new_modset: dict[str, ModCap]):
        _log.debug("Modset updated", {"new_modset": new_modset})
        on_reconf(name)

    def on_connect(new_modset: dict[str, ModCap]):
        _log.debug("Device connected", {"new_modset": new_modset})
        resync()
        if modset_eq(modset, new_modset):
            _log.debug("Supported modules unchanged")
        else:
            _log.debug("New supported modules, triggering RFS reconf", {"name": name})
            modset = new_modset
            modset_id = hash_modset(modset)
            on_reconf(name)
            return

    def set_dmc(new_dmc: DeviceMetaConfig) -> None:
        old_type = str(dmc.type) if dmc is not None else str(None)
        _log.debug("DeviceMgr.set_dmc", {"old_type": old_type, "new_dmc": json.encode(json.decode(new_dmc.to_gdata().to_json()), pretty=False)})

        if mock:
            _log.debug("DeviceMgr.set_dmc: mock device")
        else:
            new_dmc_type = new_dmc.type
            if new_dmc_type is not None:
                if old_type != str(new_dmc.type):
                    _log.debug("DeviceMgr type has changed, using new adapter", {"old_type": old_type, "new_type": new_dmc.type})

                    device_type = dev_types.get(new_dmc_type)
                    if device_type is not None:
                        adapter = device_type.adapter_type(self, device_type.schema, new_dmc, _log_handler, wcap)
                        _log.info("DeviceMgr.set_dmc: using adapter", {"adapter": adapter})
                        adapter.set_dmc(new_dmc)
                        schema = device_type.schema
                    else:
                        _log.warning("DeviceMgr.set_dmc: configured device type not available in system", {"device_type": new_dmc_type})
                else:
                    _log.debug("DeviceMgr.set_dmc: device type unchanged, not changing adapter")
            else:
                _log.debug("DeviceMgr.set_dmc: no device type configured, not changing adapter")

        adapter.set_dmc(new_dmc)

        dmc = new_dmc

    def _send_config():
        """Send configuration to the device adapter

        This function manages the transaction queue and calls the adapter's
        configure method with the current target configuration.
        """
        def on_configured(error: ?Exception, resulting_config, new_diff, new_config, old_config):
            """Handle transaction completion

            This callback is called when the adapter finishes the configuration
            transaction, either successfully or with an error.
            """
            if error is not None:
                if isinstance(error, NotConnectedError):
                    _log.debug("Device not connected, no need to retry - waiting for reconnect")
                    pending_txids.update(current_txids)
                    current_txids = set()

                elif isinstance(error, PermanentError):
                    _log.debug("Permanent error pushing configuration to device", {"error": error})
                    if isinstance(error, ConfigError):
                        _log.debug("Configuration failed due to bad config", {"error": error})

                    # Got a permanent error, giving up
                    for tid,callback in callbacks.items():
                        if tid in current_txids:
                            callback(error)
                            del callbacks[tid]

                    # TODO: uh, what else? we need to bubble up this sort of error state to an operator somehow

                    if len(pending_txids) > 0:
                        _log.debug("New intended configuration available, retrying with latest config")
                        pending_txids.update(current_txids)
                        current_txids = set()
                        _send_config()
                    else:
                        _log.debug("No new intended configuration available, no point in retrying with same conf")
                        pending_txids.update(current_txids)
                        current_txids = set()

                elif isinstance(error, TransientError):
                    _log.debug("Transient error", {"error": error})
                    if isinstance(error, BusyError):
                        _log.debug("DeviceAdapter busy, ignoring this error as adapter will trigger us once it is done with current operation")
                        return

                    if len(pending_txids) > 0:
                        _log.debug("New intended configuration available, retrying with latest config")
                        pending_txids.update(current_txids)
                        current_txids = set()
                        _send_config()
                    else:
                        retry_in = 1
                        _log.debug("No new intended configuration available. Scheduling retry of current config", {"retry_in": retry_in})
                        pending_txids.update(current_txids)
                        current_txids = set()
                        after retry_in: _send_config()

                else:
                    _log.debug("Unhandled error", {"error": error})
                    # Uh, this is indicative of programmer error and we should fix it, but let's do naive retry as well
                    pending_txids.update(current_txids)
                    current_txids = set()
                    after 1: _send_config()

            else:
                _log.debug("Configuration successfully applied on device, calling callbacks...", {"txids": current_txids})
                # Update running_conf with the result from the device (which has the new txid)
                if resulting_config is not None:
                    _log.debug("Updating running_conf with new txid", {"txid": resulting_config.txid})
                    running_conf = resulting_config
                else:
                    _log.warning("No resulting_config returned from adapter, using target_conf")
                    running_conf = target_conf

                last_sent_diff = new_diff
                for tid,callback in callbacks.items():
                    if tid in current_txids:
                        callback(True)
                        del callbacks[tid]
                current_txids = set()
                if len(pending_txids) > 0:
                    _log.debug("Configuration changed during in-progress transaction, running again...")
                    _send_config()

        # Check if we already have a transaction in progress
        if len(current_txids) > 0:
            _log.debug("DeviceMgr._send_config: there is currently an outstanding configuration, skipping", {"txids": current_txids})
            return

        # Check if there is an actual diff right now
        if running_conf is not None and target_conf is not None:
            target_conf2 = config_fixer(running_conf, target_conf)
            config_diff = yang.gdata.diff(running_conf, target_conf2) if target_conf2 is not None else None
            if config_diff is not None:
                if last_sent_diff is not None:
                    if config_diff == last_sent_diff:
                        _log.info("Reconciliation loop detected, target diff is same as last diff sent, stopping", {"diff": config_diff})
                        return
                # Actually send the configuration
                current_txids = pending_txids
                pending_txids = set()
                _log.debug("DeviceMgr._send_config: sending intended target configuration", {"txids": current_txids, "diff": config_diff})
                adapter.configure(lambda e, c: on_configured(e, c, config_diff, target_conf, running_conf), config_diff, target_conf, running_conf)
            else:
                _log.debug("DeviceMgr.configure: no diff between running and target config, nothing to do", {"txids": pending_txids})
                for tid,callback in callbacks.items():
                    if tid in pending_txids:
                        callback(True)
                        del callbacks[tid]
                pending_txids = set()
        else:
            if running_conf is None:
                _log.debug("No running config, cannot compute diff")
            if target_conf is None:
                _log.debug("No target config, cannot compute diff")

    def configure(new_conf: ?yang.gdata.Node, conf_modset_id: ?str, tid: str="0"):
        pending_txids.add(tid)
        if new_conf is not None and conf_modset_id is not None:
            if conf_modset_id != modset_id:
                _log.debug("DeviceMgr.configure: modset_id mismatch, ignoring configuration", {"conf_modset_id": str(conf_modset_id), "modset_id": str(modset_id)})
                return
            _log.debug("DeviceMgr.configure: received new intended configuration", {"tid": tid, "new_conf": truncate_conf(new_conf)})
            target_conf = new_conf
            _send_config()
        elif new_conf is None and conf_modset_id is None:
            _log.debug("DeviceMgr.configure: transaction registered intent to configure but awaiting reconf", {"tid": tid})
        else:
            _log.debug("DeviceMgr.configure: invalid input", {"conf_modset_id": str(conf_modset_id), "new_conf": truncate_conf(new_conf), "tid": tid})

    def reconfigure(cb: ?action(?Exception) -> None):
        """Reconfigure the device with the current target configuration

        This can be called in order to ensure that the device is configured
        in accordance with the current target configuration. While configuration
        changes from within Orchestron naturally trigger configuration of the
        device, it is possible that the device drifts out of sync, for example
        due to manual changes on the device. Calling reconfigure() will push
        the current target configuration to the device again.
        """
        def cb_wrapper(result: value):
            if cb is not None:
                if isinstance(result, Exception):
                    cb(result)
                else:
                    cb(None)

        reconfigure_id += 1
        new_tid = "reconfigure-{reconfigure_id}"
        pending_txids.add(new_tid)
        _send_config()
        if cb is not None:
            wait_complete(new_tid, cb_wrapper)

    def resync():
        """Ensure our view of the device running configuration is in sync with the real device

        Attempts to efficiently ensure we are in sync by using txid. If the
        device supports txid, we can avoid fetching the full config if the
        txid matches our cached version. If the device does not support txid,
        we have to fetch the full config and diff it against our cached version.
        """
        def on_fetch_config_done(new_conf: ?yang.gdata.Node, err: ?Exception) -> None:
            if err is not None:
                _log.error("Error fetching config from device", {"error": err})
            elif new_conf is not None:
                _log.debug()
                new_txid = new_conf.txid
                txid_updated = False
                running_conf_txid = None
                if running_conf is not None:
                    running_conf_txid = running_conf.txid
                    if running_conf_txid is not None:
                        if new_txid is not None:
                            if new_txid != running_conf_txid:
                                _log.debug("DeviceMgr._on_update_config: device txid changed", {"old_txid": running_conf_txid, "new_txid": new_txid, "conf": truncate_conf(new_conf)})
                                txid_updated = True
                            else:
                                _log.debug("DeviceMgr._on_update_config: device txid unchanged", {"txid": new_txid})
                        else:
                            _log.debug("DeviceMgr._on_update_config: txid not set in config from adapter, BUG?", {"conf": repr(new_conf)})
                    else:
                        _log.debug("DeviceMgr._on_update_config: txid not set in local config, BUG?", {"conf": repr(running_conf)})
                        txid_updated = True
                else:
                    _log.debug("DeviceMgr._on_update_config: no local running config, considered txid update", {"new_txid": new_txid})
                    txid_updated = True

                if txid_updated:
                    if running_conf != new_conf:
                        running_conf = new_conf
                        _log.debug("DeviceMgr._on_update_config: got new running config, reconfiguring device", {"new_txid": new_txid})
                        _send_config()
                    else:
                        _log.debug("DeviceMgr._on_update_config: got same config but with differing txid", {"new_txid": new_txid, "old_txid": running_conf_txid})

        _log.debug("DeviceMgr.resync: starting resync", {"local_device_txid": running_conf.txid if running_conf is not None else None})
        adapter.fetch_config(on_fetch_config_done)

    def wait_complete(tid: str, done: action(value)->None):
        if tid not in current_txids | pending_txids:
            _log.debug("DeviceMgr.wait_complete: transaction id not found, calling done", {"tid": tid})
            done(True) # Assume tid is very old and has already completed, thus respond immediately
        else:
            _log.debug("DeviceMgr.wait_complete: waiting for transaction to complete", {"tid": tid})
            callbacks[tid] = done

    def get_capabilities():
        return adapter.get_capabilities()

    def get_modules() -> (dict[str, ModCap], ?str):
        return modset, modset_id

    def get_config():
        """Get the running config of the device, from the adapter which keeps a cached version of it

        Note how this doesn't actually reach out to the device, but only fetches
        a local copy. However, since it is in the adapter contract to keep the
        local view of the config up to date, this is mostly quite safe!
        """
        return adapter.get_config()

    def fetch_config(done: action(?yang.gdata.Node, ?Exception) -> None) -> None:
        """Fetch the current configuration from the device
        """
        adapter.fetch_config(done)


    def get_schema():
        return schema

    def rpc_xml(cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node):
        adapter.rpc_xml(cb, xml_rpc)


class DeviceAdapter(object):
    """Abstract base class for Device Adapters
    """
    _log_handler: logging.Handler
    _wcap: ?WorldCap

    set_dmc: proc(new_dmc: DeviceMetaConfig) -> None

    ## Configure the device with the given configuration
    ##
    ## :param done: callback to call when the configuration is done
    ## :param new_diff: the diff to apply (computed by DeviceMgr)
    ## :param new_conf: the new configuration to apply
    ## :param running_conf: the current running configuration (with txid)
    configure: proc(done: action(?Exception, ?yang.gdata.Node) -> None, new_diff: yang.gdata.Node, new_conf: yang.gdata.Node, running_conf: ?yang.gdata.Node) -> None

    get_capabilities: proc() -> list[str]

    get_modules: proc() -> dict[str, ModCap]

    ## Get the current running config from the device
    ##
    ## :param done: callback to call when the operation is completed
    ##
    ## This is an async operation with the results available in the callback.
    fetch_config: proc(done: action(?yang.gdata.Node, ?Exception) -> None) -> None

    get_config: proc() -> ?yang.gdata.Node

    rpc_xml: proc(cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None


class NoAdapter(DeviceAdapter):
    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, log_handler, wcap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._log = logging.Logger(self._log_handler)

    def set_dmc(self, new_dmc):
        self._log.debug("NoAdapter.set_dmc", {"new_dmc": new_dmc.to_gdata().to_json()})

    def configure(self, done, new_diff, new_conf, running_conf):
        # The NoAdapter cannot configure anything, so we just call done() with False
        done(NotConnectedError(), None)

    def get_capabilities(self):
        return []

    def get_modules(self):
        return {}

    def fetch_config(self, done: action(?yang.gdata.Node, ?Exception) -> None):
        pass

    def get_config(self):
        pass

    def rpc_xml(self, cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None:
        pass


class MockAdapter(DeviceAdapter):
    """Mock device adapter
    """
    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, log_handler, wcap: ?WorldCap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._log = logging.Logger(self._log_handler)
        self._modset = {}
        self._dmc = None
        self._driver = MockDriver(self._dev, schema, self._log_handler, self._wcap)

    def set_dmc(self, new_dmc: DeviceMetaConfig):
        self._driver.set_dmc(new_dmc)

    def configure(self, done, new_diff, new_conf, running_conf):
        return self._driver.configure(done, new_diff, new_conf, running_conf)

    def get_capabilities(self) -> list[str]:
        return self._driver.get_capabilities()

    def get_modules(self) -> dict[str, ModCap]:
        return self._driver.get_modules()

    def fetch_config(self, done):
        return self._driver.fetch_config(done)

    def get_config(self):
        return self._driver.get_config()

    def rpc_xml(self, cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None:
        return self._driver.rpc_xml(cb, xml_rpc)


actor MockDriver(dev: DeviceMgr, schema: DeviceSchema, log_handler: logging.Handler, wcap: ?WorldCap):
    _log = logging.Logger(log_handler)
    _log.info("MockDriver starting up")

    var dmc: ?DeviceMetaConfig = None
    var modset: dict[str, ModCap] = {}

    var conn_state: int = DISCONNECTED
    var running_conf: ?yang.gdata.Node = None

    def set_dmc(new_dmc):
        if dmc is not None and new_dmc is not None:
            old_dmcg = dmc.to_gdata()
            new_dmcg = new_dmc.to_gdata()
            if old_dmcg is not None and new_dmcg is not None:
                if yang.gdata.diff(old_dmcg, new_dmcg) is not None:
                    _log.debug("Device.set_dmc: ignoring new device meta-config identical to current device meta-config")
                    return
        _log.debug("MockAdapter.set_dmc", {"new_dmc": new_dmc.to_gdata().to_json()})
        _dmc = new_dmc

        preset_caps = []
        if "cisco-ios-xr" in new_dmc.mock.preset:
            preset_caps.extend([
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg?module=Cisco-IOS-XR-um-hostname-cfg&revision=2021-04-21",
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg?module=Cisco-IOS-XR-um-interface-cfg&revision=2022-07-11",
                "http://cisco.com/ns/yang/Cisco-IOS-XR-um-if-ipv4-cfg?module=Cisco-IOS-XR-um-if-ipv4-cfg&revision=2022-07-11",
            ])
        if "juniper-junos" in new_dmc.mock.preset:
            preset_caps.extend([
                "http://xml.juniper.net/netconf/junos/1.0",
                "http://xml.juniper.net/dmi/system/1.0",
            ])
        for cap in preset_caps:
            m = parse_cap(cap)
            modset[m.name] = m
            _log.debug("Adding preset cap", {"cap": m.name})
#
        if len(new_dmc.mock.module.elements) > 0:
            for mock_cap in new_dmc.mock.module.elements:
                m = ModCap(mock_cap.name, mock_cap.namespace, mock_cap.revision, mock_cap.feature)
                _log.debug("Adding mock cap", {"cap": m.name})
                modset[m.name] = m

        if len(modset) > 0:
            _log.debug("Mock capabilities set, \"connecting\"...")
            conn_state = CONNECTED
            running_conf = yang.gdata.Container()
            dev.on_connect(modset)
        else:
            _log.debug("No mock capabilities set, idling as not connected")

    def configure(done, new_diff, new_conf, running_conf):
        if conn_state == CONNECTED:
            _log.debug("MockAdapter.configure: device 'connected', responding done")
            running_conf = new_conf
            done(None, new_conf)
        else:
            _log.debug("MockAdapter.configure: device not connected")
            done(NotConnectedError(), None)

    def get_capabilities():
        return []

    def get_modules():
        return modset

    def fetch_config(done):
        done(running_conf, None)

    def get_config():
        return running_conf

    def rpc_xml(cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None:
        cb(xml.Node("ok"), None)


class NetconfAdapter(DeviceAdapter):

    def __init__(self, dev: DeviceMgr, schema: DeviceSchema, init_dmc: DeviceMetaConfig, log_handler, wcap: ?WorldCap):
        self._dev = dev
        self._schema = schema
        self._log_handler = log_handler
        self._wcap = wcap
        self._driver = NetconfDriver(self._dev, self._schema, init_dmc, self._log_handler, self._wcap)

    def set_dmc(self, new_dmc: DeviceMetaConfig):
        self._driver.set_dmc(new_dmc)

    def configure(self, done, new_diff, new_conf, running_conf):
        return self._driver.configure(done, new_diff, new_conf, running_conf)

    def get_capabilities(self) -> list[str]:
        return self._driver.get_capabilities()

    def get_modules(self) -> dict[str, ModCap]:
        return self._driver.get_modules()

    def fetch_config(self, done: action(?yang.gdata.Node, ?Exception) -> None) -> None:
        self._driver.fetch_config(done)

    def get_config(self):
        return self._driver.get_config()

    def close(self, on_close: ?action() -> None=None):
        """Close the connection to the device
        """
        self._driver.close(on_close)

    def rpc_xml(self, cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None:
        return self._driver.rpc_xml(cb, xml_rpc)


actor NetconfDriver(dev: DeviceMgr, schema: DeviceSchema, init_dmc: DeviceMetaConfig, log_handler: logging.Handler, wcap: ?WorldCap):
    """NETCONF device adapter

    It is possible to configure a device using different transaction commit
    procedures. Devices that have the writable-running capability allow
    edit-config RPC to directly target the running datastore so that we can push
    an entire configuration in a single operation which implicitly also
    "commits". This is often ideal since we can easily form the complete
    configuration as a single config payload to apply with a single RPC.

    Many devices support a candidate datastore ("candidate" capability) to which
    configuration can first be pushed, possibly using multiple edit-config
    calls, and then committed at which point the configuration goes from the
    candidate datastore to running. This mimics CLI use by a human where a
    configuration session to candidate allows editing the configuration in
    multiple operations and reviewing the result before a commit is performed.
    There is no real inherent benefit of using candidate mode for a system like
    Orchestron, the one exception being that it enables the use of confirmed
    commits (another capability).

    Confirmed commits enables a confirmation timeout for a commit, so that after
    the commit is performed, it must be confirmed within this time period or it
    is rolled back. This allows the device to rollback a potentially bad change
    if it means we lost connectivity to the device and thus we weren't able to
    confirm the commit. This is ideal from a network automation perspective
    since we get sort of built-in support for rolling back bad changes.

    Some devices do not support writable-running but do support candidate, such
    as IOS XR, which forces us to always go through the candidate datastore.

    In order of preference, we have these alternative commit procedures:
    - write to candidate + confirmed-commit, if confirmed-commit is supported
    - write directly to running, if writable-running is supported
    - write to candidate + commit

    What we actually push to the device is a diff that is computed based on the
    current running configuration which we fetch from the device and the new
    target configuration that we computed from the transforms in the TTT
    transaction engine. The diff is then pushed to the device. To ensure correct
    operations, we take a lock on the datastore on the device for the duration
    of the entire commit procedure.

    """
    _log = logging.Logger(log_handler)
    _log.info("NetconfDriver starting up")
    _con_log_handler = logging.Handler("ssh")
    _con_log_handler.set_handler(log_handler)

    # The currently running configuration on the device (which in NMDA lingo is
    # the "intended configuration" of the device)
    var running_conf: ?yang.gdata.Node = None

    # The device's meta configuration, like address, credentials, etc.
    var dmc: DeviceMetaConfig = init_dmc

    # The NETCONF client connection to the device
    var client: ?netconf.Client = None

    var state: int = DISCONNECTED

    var modset: dict[str, ModCap] = {}

    NS_NC_1_0 = "urn:ietf:params:xml:ns:netconf:base:1.0"

    def _on_connect(c: netconf.Client, err):
        if client is not None and c is not client:
            _log.debug("Device._on_connect: ignoring connection from old client")
            return

        if err is not None:
            if state == CONNECTING:
                _log.error("Device._on_connect: error connecting to device", {"error": str(err)})
            else:
                _log.debug("Device._on_connect: connection failed", {"error": str(err)})
            modset = {}
            if client is not None:
                after 1: client.restart()
            return
        else:
            _log.info("Device._on_connect: connected to device")
            state = CONNECTED

            new_modset: dict[str, ModCap] = {}
            for cap in c.get_capabilities():
                m = parse_cap(cap)
                new_modset[m.name] = m

            # TODO: check yang-library instead!!

            if not modset_eq(modset, new_modset):
                modset = new_modset

            dev.on_connect(modset)

    def _on_notif(c, n):
        if client is not None and c is not client:
            _log.debug("Device._on_connect: ignoring connection from old client")
            return
        _log.debug("Notification from device")

    def set_dmc(new_dmc: DeviceMetaConfig):
        _log.debug("Device.set_dmc", {"dmc": dmc.to_gdata().to_json(), "new_dmc": new_dmc.to_gdata().to_json()})
        # TODO: implement Eq for adata
        #if dmc is not None and dmc == new_dmc:
        if dmc is not None and new_dmc is not None:
            old_dmcg = dmc.to_gdata()
            new_dmcg = new_dmc.to_gdata()
            if old_dmcg is not None and new_dmcg is not None:
                if old_dmcg == new_dmcg:
                    _log.debug("Device.set_dmc: ignoring new device meta-config identical to current device meta-config")
                    return

        con_log_level = logging.TRACE if dmc.debug.connection else logging.WARNING
        _con_log_handler.set_output_level(con_log_level)

        _connect(new_dmc)
        dmc = new_dmc

    def _connect(new_dmc):
        if not len(new_dmc.address.elements) > 0:
            _log.debug("Not enough addressess :/")
            return

        addr = new_dmc.address.elements[0]
        address = addr.address
        addr_port = addr.port
        port = addr_port if addr_port is not None else 830
        username = new_dmc.credentials.username
        password = new_dmc.credentials.password

        # TODO: we only need o use a new client if connection parameters have
        # changed, other settings don't require a new client

        if wcap is not None and password is not None:
            state = CONNECTING
            _log.debug(f"Setting up NETCONF client... {address} {port} {username} {password}")
            c = netconf.Client(wcap, address, port, username, password,
                               skip_host_key_check=True,
                               on_connect=_on_connect,
                               on_notif=_on_notif,
                               log_handler=_con_log_handler)
            client = c

    # TODO: Close protocol
    def close(on_close: ?action() -> None=None):
        """Close the connection to the device
        """
        _log.debug("Device.close")
        if client is not None:
            client.close()
            state = DISCONNECTED
            _log.debug("Device closed")
        else:
            _log.debug("Device.close: No client, nothing to close")
        if on_close is not None:
            on_close()

    # TODO: Restart protocol
    def restart():
        """Close the existing connection and reconnect to the device
        """
        _log.debug("Device.restart")
        new_dmc = dmc
        close(lambda: _connect(new_dmc))

    def attach_txid(conf: yang.gdata.Node, new_txid) -> yang.gdata.Node:
        """Attach a txid to a configuration node"""
        if isinstance(conf, yang.gdata.Container):
            return yang.gdata.Container(
                children=conf.children,
                presence=conf.presence,
                ns=conf.ns,
                module=conf.module,
                txid=new_txid)
        raise ValueError("Can only attach txid to Container")

    def get_txid(done: action(netconf.Client, str, ?yang.gdata.Node) -> None):
        """Get txid from device

        Dispatches to device-specific txid retrieval methods.
        Returns client, txid as string, and optionally the full config if it was fetched.
        """
        _log.debug("Device.get_txid: fetching txid")

        if client is None:
            _log.error("Device.get_txid: no client connection")
            raise NotConnectedError()

        if is_junos():
            get_txid_junos(done)
        else:
            get_txid_generic(done)

    def get_txid_junos(done: action(netconf.Client, str, ?yang.gdata.Node) -> None):
        """Get txid for JUNOS devices - try to extract junos:commit-seconds first"""
        _log.debug("Device.get_txid_junos: fetching minimal config for txid")

        def on_junos_txid_data(c: netconf.Client, r: ?xml.Node, error: ?netconf.NetconfError):
            """Process JUNOS config data to extract txid"""
            if error is not None:
                _log.error("Device.get_txid_junos: error fetching config", {"error": error})
                # Fall back to generic method on error
                get_txid_generic(done)
            elif r is not None:
                # Extract current config and try to get junos:commit-seconds
                data_tag = r.children[0] if len(r.children) > 0 else None
                if data_tag is not None:
                    # Try to extract JUNOS txid from attributes
                    txid = extract_txid(data_tag)
                    if txid is not None:
                        _log.debug("Device.get_txid_junos: extracted JUNOS txid", {"txid": txid})
                        # Return client and txid string, no config since we only have a subtree
                        done(c, txid, None)
                    else:
                        _log.warning("Device.get_txid_junos: no junos:commit-seconds found, falling back to generic")
                        # Fallback to generic method - fetch full config and hash
                        get_txid_generic(done)
                else:
                    _log.error("Device.get_txid_junos: no data in response")
                    get_txid_generic(done)
            else:
                _log.error("Device.get_txid_junos: no response")
                get_txid_generic(done)

        # Fetch minimal config with JUNOS filter to get txid
        # We need to fetch a valid configuration node that actually exists.
        # Since we are communicating over NETCONF/SSH, we can safely fetch
        # the netconf ssh node, knowing that it should always exist
        filter = xml.Node("filter", children=[
            xml.Node("configuration", children=[
                xml.Node("system", children=[
                    xml.Node("services", children=[
                        xml.Node("netconf", children=[
                            xml.Node("ssh")
                            ])
                        ])
                    ])
                ])
            ])
        if client is not None:
            client.get_config(on_junos_txid_data, "running", filter)
        else:
            raise NotConnectedError()

    def get_txid_generic(done: action(netconf.Client, str, ?yang.gdata.Node) -> None):
        """Get txid for generic devices - fetch full config and hash it"""
        _log.debug("Device.get_txid_generic: fetching full config for hash")

        def on_generic_txid_data(c: netconf.Client, r: ?xml.Node, error: ?netconf.NetconfError):
            if error is not None:
                _log.error("Device.get_txid_generic: error fetching config", {"error": error})
                # Can't recover from this, return empty txid
                done(c, "", None)
            elif r is not None:
                _log.debug("Device.get_txid_generic: got full config")
                # Extract current config and compute hash
                data_tag = r.children[0] if len(r.children) > 0 else None
                if data_tag is not None:
                    current = schema.from_xml(data_tag)
                    if current is not None:
                        # Compute hash of the entire config as txid
                        current_xml_bytes = current.to_xmlstr().encode()
                        conf_hash = str(wyhash.hash(0, current_xml_bytes))
                        _log.debug("Device.get_txid_generic: computed config hash", {"hash": conf_hash})

                        # Attach txid to config
                        current_with_txid = attach_txid(current, conf_hash)

                        # Update running_conf since we have the full config
                        running_conf = current_with_txid
                        _log.debug("Device.get_txid_generic: updated running_conf")

                        # Return client, txid and full config
                        done(c, conf_hash, current_with_txid)
                    else:
                        _log.error("Device.get_txid_generic: failed to parse config")
                        done(c, "", None)
                else:
                    _log.error("Device.get_txid_generic: no data in response")
                    done(c, "", None)
            else:
                _log.error("Device.get_txid_generic: no response")
                done(c, "", None)

        # Fetch full config for hashing
        if client is not None:
            client.get_config(on_generic_txid_data, "running")
        else:
            raise NotConnectedError()

    def configure(done, new_diff, new_conf, old_conf):
        """Configure the device with a new configuration

        This starts a multi-step transaction process:
        1. Lock the datastore
        2. Fetch current config from device
        3. Compute diff between current and target
        4. Send diff via edit-config
        5. Commit (if using candidate datastore)
        6. Unlock datastore
        """
        _log.debug("Device.configure: received new configuration")

        # Check state
        if state != CONNECTED:
            if state == DISCONNECTED:
                _log.debug("Device.configure: device not connected, cannot send configuration")
                done(NotConnectedError(), None)
            else:
                _log.debug("Device.configure: Already in transaction, cannot send configuration")
                done(BusyError(), None)
            return

        # Set transaction state
        state = TRANSACTION

        def on_locked_running(c: netconf.Client, error: ?netconf.NetconfError):
            """Callback after locking running datastore"""
            _log.debug("Device.configure.on_locked_running", {"error": error})
            if error is not None:
                abort(error)
            else:
                if target_datastore() == "candidate":
                    # Now lock candidate as well
                    _log.debug("Device.configure: locking candidate datastore")
                    c.lock(on_locked_candidate, "candidate")
                else:
                    # Just running is enough, get the txid
                    _log.debug("Device.configure: getting txid")
                    get_txid(on_txid_received)

        def on_locked_candidate(c: netconf.Client, error: ?netconf.NetconfError):
            """Callback after locking candidate datastore"""
            _log.debug("Device.configure.on_locked_candidate", {"error": error})
            if error is not None:
                # If we had locked running first, unlock it
                if has_writable_running():
                    c.unlock(lambda c, e: abort(error), "running")
                else:
                    abort(error)
            else:
                _log.debug("Device.configure: getting txid before configuration")
                get_txid(on_txid_received)

        def on_txid_received(c: netconf.Client, current_txid: str, current_conf: ?yang.gdata.Node):
            """Called after txid has been retrieved from device"""
            # Check if txid matches our expected
            expected_txid = old_conf.txid if old_conf is not None else None

            _log.debug("Device.configure: validating txid", {"expected": expected_txid, "current": current_txid})

            if expected_txid is not None and current_txid != expected_txid:
                _log.error("Device.configure: txid mismatch - configuration drift detected",
                          {"expected": expected_txid, "current": current_txid})
                abort(TxidMismatchError(f"Configuration drift detected: expected txid {expected_txid}, got {current_txid}"))
            else:
                # txid matches or no expected txid, proceed with configuration
                # If we got a full config from get_txid_generic, update our running_conf
                if current_conf is not None:
                    _log.debug("Device.configure: using updated running_conf from get_txid_generic")
                    running_conf = current_conf

                # Use the diff provided by DeviceMgr
                xml_diff = new_diff.to_xmlstr(pretty=False)
                if xml_diff != "":
                    _log.debug("Device.configure: sending diff", {"diff": xml_diff})
                    if client is not None:
                        client.edit_config(xml_diff, on_edited, target_datastore())
                else:
                    _log.debug("Device.configure: no changes needed")
                    if client is not None:
                        complete(client)
                    else:
                        abort(NotConnectedError())

        def on_edited(c: netconf.Client, error: ?netconf.NetconfError):
            _log.debug("Device.configure.on_edited", {"error": error})
            if error is not None:
                _log.error("Device.configure: edit-config error", {"error": error})
                abort(ConfigError("Failed to edit config: " + str(error.error_message), conf=new_conf, target_conf=new_conf))
            else:
                if target_datastore() == "candidate":
                    _log.debug("Device.configure: committing to candidate")
                    c.commit(on_committed)
                else:
                    _log.debug("Device.configure: edit-config complete (writable-running)")
                    complete(c)

        def on_committed(c: netconf.Client, error: ?netconf.NetconfError):
            _log.debug("Device.configure.on_committed", {"error": error})
            if error is not None:
                _log.error("Device.configure: commit error", {"error": error})
                # Check error tag to determine type
                error_tag = None
                rpc_error = error.rpc_error
                if rpc_error is not None and len(rpc_error) > 0:
                    error_tag = rpc_error[0].error_tag

                _log.debug("Device.configure: discarding changes after failed commit")
                # Check if the error is due to locked datastore
                if error_tag == "in-use":
                    c.discard_changes(lambda c, e: abort(LockedError("Datastore is locked")))
                else:
                    c.discard_changes(lambda c, e: abort(ConfigError("Commit failed: " + str(error.error_message), conf=new_conf, target_conf=new_conf)))
            else:
                _log.debug("Device.configure: commit successful")
                complete(c)

        def complete(c: netconf.Client):
            """Successfully complete the transaction"""
            _log.debug("Device.configure: transaction complete, fetching new txid")

            def on_resulting_txid(c: netconf.Client, txid: str, final_conf: ?yang.gdata.Node):
                """Called with the new txid after configuration is complete"""
                _log.debug("Device.configure: got new txid", {"txid": txid})
                # If we got a full config, update our running_conf
                if final_conf is not None:
                    running_conf = final_conf
                    finish_with_config(final_conf)
                else:
                    # For JUNOS, we only got the txid, so create a config with
                    # the new txid based on the target config we just applied.
                    # Note how we take an optimistic view here and assume that
                    # the device operatores correctly, i.e. that applying the
                    # diff we sent to it will result in its running
                    # configuration being exactly like our target configuration.
                    # There are many situations in real life that voids this,
                    # e.g. platform-specific config mutations.
                    new_conf_with_txid = attach_txid(new_conf, txid)
                    running_conf = new_conf_with_txid
                    finish_with_config(new_conf_with_txid)

            def finish_with_config(conf):
                """Finish with unlocking and calling done with the config"""
                def on_candidate_unlocked(c2: netconf.Client, e: ?netconf.NetconfError):
                    # If we locked running, unlock it after candidate (reverse order of locking)
                    if has_writable_running():
                        c2.unlock(lambda c3, e2: finish(e if e is not None else e2, conf), "running")
                    else:
                        finish(e, conf)

                if use_locks():
                    if target_datastore() == "candidate":
                        # Unlock candidate first
                        c.unlock(on_candidate_unlocked, "candidate")
                    elif has_writable_running():
                        # Just unlock running (we were using writable-running)
                        c.unlock(lambda c3, e: finish(e, conf), "running")
                    else:
                        # Shouldn't happen, but handle gracefully
                        finish(None, conf)
                else:
                    finish(None, conf)

            # Get the new txid after configuration
            get_txid(on_resulting_txid)

        def abort(err: Exception):
            """Abort and cleanup the transaction"""
            _log.debug("Device.configure: aborting transaction", {"error": err})

            def on_abort_candidate_unlocked(c: netconf.Client, e: ?netconf.NetconfError):
                # If we locked running, unlock it after candidate (reverse order)
                if has_writable_running():
                    c.unlock(lambda c2, e2: finish(err), "running")
                else:
                    finish(err)

            if client is not None:
                if target_datastore() == "candidate":
                    # Unlock candidate first
                    client.unlock(on_abort_candidate_unlocked, "candidate")
                elif has_writable_running():
                    # Just unlock running (we were using writable-running)
                    client.unlock(lambda c, e: finish(err), "running")
                else:
                    # No locks to release
                    finish(err)
            else:
                finish(err)

        def finish(error: ?Exception=None, final_conf: ?yang.gdata.Node=None):
            """Final cleanup and state reset"""
            _log.debug("Device.configure: finishing transaction", {"error": error})
            # Reset state to CONNECTED
            state = CONNECTED
            # Call the done callback
            if error is not None:
                done(error, None)
            else:
                # Return the final config with its new txid
                result_conf = final_conf if final_conf is not None else new_conf
                done(None, result_conf)

        # Start the transaction by locking the datastore(s)
        # Lock running if it's writable (to prevent others from directly editing it)
        # Otherwise, just lock the target datastore
        if client is not None:
            if use_locks():
                if has_writable_running():
                    _log.debug("Device.configure: starting transaction, locking running datastore")
                    client.lock(on_locked_running, "running")
                elif target_datastore() == "candidate":
                    _log.debug("Device.configure: starting transaction, locking candidate datastore only")
                    client.lock(on_locked_candidate, "candidate")
                else:
                    # This shouldn't happen - we should have either writable-running or candidate
                    _log.error("Device.configure: No lockable datastore available")
                    abort(ValueError("No lockable datastore available"))
            else:
                _log.debug("Device.configure: Not using locks, getting txid")
                get_txid(on_txid_received)


    def get_capabilities():
        if client is not None:
            return client.get_capabilities()
        return []

    def get_modules():
        return modset

    def use_locks():
        # TODO: enable locks per default? or config option?
        # Locking is disabled per default.
        return False
        # Nokia SR Linux seems to be broken. The first commit dance in a NETCONF
        # session always seem to work, but if we have first acquired the lock on
        # candidate (Nokia SRL has candidate, not writable-running), the second
        # commit fails with a cryptic error message:
        # <rpc-error>
        #     <error-type>application</error-type>
        #     <error-tag>operation-failed</error-tag>
        #     <error-severity>error</error-severity>
        #     <error-message>
        #     Error [InvalidArgument]: Cannot discard candidate without starting a configuration session (request session id 17)
        #     </error-message>
        # </rpc-error>
        if is_nokia_srl():
            return False
        return True

    def target_datastore():
        # In order of preference, we have these alternative commit procedures:
        # - write to candidate + confirmed-commit, if confirmed-commit is supported
        # - write directly to running, if writable-running is supported
        # - write to candidate + commit
        if has_confirmed_commit() and has_candidate():
            return "candidate"
        elif has_writable_running():
            return "running"
        elif has_candidate():
            return "candidate"

        raise ValueError("No writable datastore available")

    def has_candidate():
        return "urn:ietf:params:netconf:capability:candidate:1.0" in modset

    def has_confirmed_commit():
        return "urn:ietf:params:netconf:capability:confirmed-commit:1.0" in modset

    def has_writable_running():
        return "urn:ietf:params:netconf:capability:writable-running:1.0" in modset

    def is_junos():
        for m in modset.values():
            if "junos" in m.name:
                return True
        return False

    def is_nokia_srl():
        return "srl_nokia-aaa" in modset

    def fetch_config(done: action(?yang.gdata.Node, ?Exception) -> None) -> None:
        def on_get_config(c, r, error):
            if error is not None:
                _log.error("Device._on_get_config: error", {"error": error.error_message})
                # TODO: refine this error handling, at least down to transient vs permanent
                done(None, ValueError("Failed to get config: " + str(error.error_message)))
            elif r is not None:
                if r.tag == "rpc-reply" and len(r.children) == 1 and r.children[0].tag == "data":
                    _log.debug("Device.on_get_config", {"r": r.encode()})
                    data_tag = r.children[0]
                    txid = None
                    # JUNOS response looks like this
                    # <data>\n<configuration xmlns="http://xml.juniper.net/xnm/1.1/xnm" junos:commit-seconds="1756279893" junos:commit-localtime="2025-08-27 07:31:33 UTC" junos:commit-user="root">
                    # We want to extract the junos:commit-seconds and attach as txid on the root node in running_conf
                    new_conf = schema.from_xml(r.children[0])
                    if new_conf is not None:
                        if new_conf.txid is None:
                            txid = extract_txid(data_tag)
                            if txid is not None:
                                # attach new txid by constructing new root Node since gdata.Node is immutable
                                _log.debug("Device.on_get_config: attaching extracted txid to new_conf", {"txid": txid})
                                new_conf = attach_txid(new_conf, txid)
                            else:
                                # No txid in response, fallback to hashing the XML
                                new_conf_xml_bytes = new_conf.to_xmlstr().encode()
                                conf_hash = str(wyhash.hash(0, new_conf_xml_bytes))
                                _log.debug("Device.on_get_config: computed txid hash from config", {"txid": conf_hash})
                                new_conf = attach_txid(new_conf, conf_hash)
                        else:
                            _log.debug("Device.on_get_config: parsed config already has txid", {"txid": new_conf.txid})

                    # Save our own (in Adapter) view of the device's running configuration
                    running_conf = new_conf
                    done(running_conf, None)
                else:
                    _log.error("Device.on_get_config", {"r": r.encode()})
                    done(None, ValueError("Unexpected response to <get-config>"))

        _log.debug("Device._fetch_config")
        if client is not None:
            client.get_config(on_get_config)

    def get_config():
        return running_conf

    def rpc_xml(cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node) -> None:
        def rpc_reply(c, r: ?xml.Node, error: ?netconf.NetconfError):
            _log.debug("Device.rpc_xml.rpc_reply", {"r": r, "error": error})
            cb(r, error)

        _log.debug("Device.rpc_xml", {"xml_rpc": xml_rpc})
        if client is not None:
            client.rpc(xml_rpc, rpc_reply)

    _connect(dmc)


class DeviceTreeProvider(yang.gdata.TreeProvider):
    dev: DeviceMgr

    def __init__(self, dev: DeviceMgr):
        self.dev = dev

    # TODO: remove this, standardize on gdata
    proc def rpc_xml(self, cb: action(?xml.Node, ?Exception) -> None, xml_rpc: xml.Node):
        self.dev.rpc_xml(cb, xml_rpc)

    proc def rpc(self, cb: action(?yang.gdata.Node, ?Exception) -> None, rpc_input: yang.gdata.Node):
        pass
        # self.dev.rpc(cb, rpc_input)


def hash_modset(modset: dict[str, ModCap]) -> str:
    # TODO: use a better hash function
    # We use map here instead of a list comprehension to avoid creating the
    # intermediate list of strings. Ideally we could achieve the same with a
    # generator expression.
    modset_str = map(lambda m: str(modset[m]), sorted(modset.keys()))
    return str(hash("".join(modset_str)))

def modset_eq(a: dict[str, ModCap], b: dict[str, ModCap]) -> bool:
    if len(a) != len(b):
        return False
    if set(a.keys()) != set(b.keys()):
        return False
    for k in a.keys():
        if a[k] != b[k]:
            return False
    return True


def parse_cap(tcap: str) -> ModCap:
    parts = tcap.split("?", 1)

    name = parts[0]
    namespace = parts[0]
    revision = None
    feature = []

    qps = {}
    if len(parts) > 1:
        qparts = parts[1].split("&")
        for qpart in qparts:
            qkvparts = qpart.split("=")
            if len(qkvparts) == 2:
                qk, qv = qkvparts[0], qkvparts[1]
                qps[qk] = qv

    if "module" in qps:
        name = qps["module"]
    if "revision" in qps:
        revision = qps["revision"]

    return ModCap(name, namespace, revision, feature)


def _test_parse_cap_base():
    mod = parse_cap("urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.name, "urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.namespace, "urn:ietf:params:netconf:base:1.1")
    testing.assertEqual(mod.revision, None)
    testing.assertEqual(mod.feature, [])

def _test_parse_cap_xr_isis():
    mod = parse_cap("http://cisco.com/ns/yang/Cisco-IOS-XR-isis-act?module=Cisco-IOS-XR-isis-act&revision=2019-10-01")
    testing.assertEqual(mod.name, "Cisco-IOS-XR-isis-act")
    testing.assertEqual(mod.namespace, "http://cisco.com/ns/yang/Cisco-IOS-XR-isis-act")
    testing.assertEqual(mod.revision, "2019-10-01")
    testing.assertEqual(mod.feature, [])

def _test_parse_cap_xr_hostname():
    mod = parse_cap("http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg?module=Cisco-IOS-XR-um-hostname-cfg&revision=2021-04-21")
    testing.assertEqual(mod.name, "Cisco-IOS-XR-um-hostname-cfg")
    testing.assertEqual(mod.namespace, "http://cisco.com/ns/yang/Cisco-IOS-XR-um-hostname-cfg")
    testing.assertEqual(mod.revision, "2021-04-21")
    testing.assertEqual(mod.feature, [])

def extract_txid(conf: ?xml.Node) -> ?str:
    """Attempt to extract a txid from configuration

    On JUNOS we use commit-seconds, which is a proprietary extension that JUNOS
    sets as an XML attribute on the configuration XML tag
    """
    if conf is not None:
        if len(conf.children) == 1 and conf.children[0].tag == "configuration":
            configuration_tag = conf.children[0]
            for attr_name, attr_value in configuration_tag.attributes:
                if attr_name == "junos:commit-seconds":
                    return attr_value

def config_fixer(old: ?yang.gdata.Node, new: yang.gdata.Node):
    # Fix up config. On IOS XR we need to bring with us the Mgmt interface
    # configuration that exists on the device. We run XRds for testing using
    # containerlab and containerlab configures the IP addresses as part of a
    # bootstrap process. The IP addresses are dynamically allocated and thus
    # vary between test invocations. Since our transform output does not contain
    # any configuration of the MgmtEth0/RP0/CPU0/0 interface, the diff will
    # remove it. If we deconfigure the interface from the device, we loose
    # connectivity to it. This code simply finds if there is a
    # MgmtEth0/RP0/CPU0/0 interface in the currently running configuraton on the
    # device and then brings that over into the new target config.
    def get_xr_mgmt_interface(n: ?yang.gdata.Node) -> yang.gdata.Node:
        if n is not None:
            xr_interfaces = n.children["interfaces"]
            if xr_interfaces.ns != "http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg":
                raise ValueError("No XR interfaces found")
            xr_interface = xr_interfaces.children["interface"]
            if isinstance(xr_interface, yang.gdata.List):
                for elem in xr_interface.elements:
                    if_name = elem.get_leaf("interface-name").val
                    if isinstance(if_name, str):
                        if if_name == "MgmtEth0/RP0/CPU0/0":
                            return yang.gdata.Container({
    'interfaces': yang.gdata.Container({
        'interface': yang.gdata.List(['interface-name'], elements=[elem])
    }, ns='http://cisco.com/ns/yang/Cisco-IOS-XR-um-interface-cfg', module='Cisco-IOS-XR-um-interface-cfg')
    })
        raise ValueError("No XR mgmt interface found")

    try:
        mgmt_intf_cfg = get_xr_mgmt_interface(old)
        new2 = yang.gdata.patch(new, mgmt_intf_cfg)
        if new2 is not None:
            return new2
        raise ValueError("Unreachable, patch will never produce empty (None) config for this config input")
    except Exception as exc:
        pass
    return new
